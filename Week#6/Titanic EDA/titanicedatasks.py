# -*- coding: utf-8 -*-
"""TitanicEDATasks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A127J6r5xdUQIs-SH6EihHJXvCFIEYQ9

- Try to impute Missing Values in "Embarked" feature instead of Dropping

- Create New Feature: "family_size" to combine "parch" and " sibsp" and explore it with Survival Rate

- How many passengers were alone? What is their Survival Rate ?

- What are top 3 categories from "family_size" have highest survival Rate ?

- Hint : search for sort_values and nlargest methods

- Try differnet age groups

- Which age groups have the lowest and highest survival rate for both females and males?
"""

#!pip install -q kaggle

#from google.colab import files
#files.upload()

#!mkdir ~/.kaggle
#!cp kaggle.json ~/.kaggle/
#!chmod 600 ~/.kaggle/kaggle.json

#!kaggle competitions download -c titanic

#!unzip titanic.zip

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

df = pd.read_csv('train.csv')
df.columns = df.columns.str.lower()
df.info()

df.describe()

df.sample()

"""First we need to drop all the Unnecessary columns for this example will drop:<br>
- PassengerId  
- Name         
- Ticket       
- Cabin
"""

df.drop(['passengerid', 'name', 'ticket', 'cabin'], axis=1, inplace=True)

df.isnull().sum()

df.isnull().mean()*100

"""### **You see here that ≈ 20% of Ages, and ≈ 0.22% of Embarked are missing**

# Data Imputation
try to impute the missing values in the Embarked column <br>
we can see that the Embraked is categorical data so we use on of the following methods:<br>
- Mode imputation ( fill missing data with most repeated value)
- Group-based mode imputation (if the data depends on another feature)
- “Unknown” or “Missing” category (if the missing means something)
- Using sklearn (good for pipelines)

--------------------------------------------------------------------
in this section will try to see if any of other features has correlation with the embarked feature using heatmap <br>
but first we need to convert the embarked from catigorical to numerical values <br>
and since the values doesn't have order we can use either label encoding or the map function
"""

df_test = df.copy()

df_test['EncodedEmbarked'] = df['embarked'].map({'C':0,'Q':1,'S':2,'Nan':3})
df_test['EncodedSexes'] = df['sex'].map({'male':0,'female':1})

"""C => 0 <br>
Q => 1 <br>
S => 2 <br>
Nan => 3 <br>
----------------------------------------------------- <br>
Male => 0 <br>
Female => 1
"""

df_test.drop(['embarked','sex'], axis=1, inplace=True)

sns.heatmap(df_test.corr(),annot=True,cmap='coolwarm',linewidths=0.5,linecolor='white',annot_kws={"size":10})

"""## As shown above there are no strong correlations with the embarked feature so we can easly use the mode to replace the missing values"""

df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)

df.isnull().sum()

"""##Creating new feature<br>
now we need to combine parch and sibsp featrues to make a new feature called family_size and use it to explore the survived ratings
"""

df['family_size']=df['parch']+df['sibsp']
#df.drop(['parch','sibsp'], axis=1, inplace=True) #this one is optional

df.sample(5)

plt.figure(figsize=(15,11))
plt.pie(df['family_size'].value_counts(), labels=df['family_size'].value_counts().index, autopct='%1.1f%%')
plt.title('Family Size Distribution')
plt.show()

plt.figure(figsize=(15,8))
sns.barplot(x='family_size', y=(df['survived']*100), data=df , hue='sex')
plt.title('Survival Rate by Family Size')
plt.ylabel('Survival Rate')
plt.show()

familySurvivalRate = df.groupby('family_size')['survived'].mean().sort_values(ascending=False) *100
familySurvivalRate

"""As you can see the 3 top family_size categories that have the highest surviving rate are 3,2,1 respectively

## Age Groups <br>
now we will divide Ages to number of groups <br>
but first we need to make sure that we don't have any missing values
"""

df.isnull().sum()

df.groupby(["sex", "pclass", "embarked", "family_size"])['age'].mean()

from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=2)
df[['age']] = imputer.fit_transform(df[['age']])

df.isnull().sum()

df.age.hist(bins=20)

"""The Titanic sank on 15 April 1912 so we are going to divide the groups based on the generations the people were born into"""

df['generation'] = pd.cut(df['age'],
    bins=[0, 2, 11, 29, 41, 70],
    labels=['Greatest Gen (1910-1912)',
            'Early 20th (1901-1909)',
            'Lost Generation (1883-1900)',
            'Victorian / Gilded (1870-1882)',
            'Pre-Victorian (<=1869)'])

plt.figure(figsize=(15,8))
sns.barplot(x='generation', y=(df['survived']*100), data=df , hue='sex')
plt.xlabel('Generation')
plt.title('Survival Rate by Generation')
plt.ylabel('Survival Rate')
plt.tight_layout()
plt.show()

df.groupby(['generation','sex'])['survived'].mean()*100

"""As show above
- the highest survival rate for males are the      Greatest Gen (1910-1912)
- the highest survival rate for females are the    Pre-Victorian (<=1869)
- the lowest survival rate for males are the       Lost Generation (1883-1900)
- the lowest survival rate for females are the     Early 20th (1901-1909)
"""

sns.pairplot(df, hue='survived')
plt.tight_layout()
# -*- coding: utf-8 -*-
"""Numpy Assignments R1024#286.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SCSG_a-tkyh0M4EbGIg18f6WdMvKimZA

<a href="https://www.zero-grad.com/">
         <img alt="Zero Grad" src="https://i.postimg.cc/y8LZ0CM6/linear-Algebra.png" >
      </a>

# ðŸ§ª Assignment 1: Build Your Own `train_test_split_np()` Using NumPy

##  Introduction:

In Machine Learning, we build models that **learn from data** and then **make predictions** on new, unseen data.

But if we train and test our model on the same data, we won't know if it's actually good â€” it might just be memorizing the data (overfitting). To avoid this, we **split the dataset** into two parts:

- **Training Set** ðŸ§   
  Used by the model to learn patterns from data.

- **Testing Set** ðŸ§ª  
  Used to evaluate how well the model performs on new, unseen data.

This approach helps us **estimate how the model will perform in the real world**.

---

### âš–ï¸ Common Split Ratios

- **80% Train / 20% Test** â€“ most common for general tasks.
- **70% Train / 30% Test** â€“ when you want more test data.
- **90% Train / 10% Test** â€“ if your dataset is large.

There's no one "right" ratio â€” it depends on your dataset size and use case.

---

### ðŸ”€ Should We Shuffle the Data?

Yes!  
If your data is ordered (e.g. time-based), you should **shuffle** it before splitting to avoid bias.

Shuffling ensures that both the training and test sets represent the overall data distribution fairly.

---

### ðŸ§  Real-Life Analogy

Imagine you're studying for an exam.

- You **practice with sample questions** (training set).
- Then you **test yourself with new questions** you've never seen (test set).

If you only "test" yourself using the same practice questions, you're not really testing your understanding â€” you're just repeating.

---

### ðŸ§ª Summary

| Term           | Purpose                          |
|----------------|----------------------------------|
| Training Set   | Learn from it                    |
| Testing Set    | Evaluate model on unseen data    |
| Shuffle        | Avoid bias from data order       |
| Test Ratio     | Controls how much data is held out for testing |

Understanding this concept is the first step toward building reliable, real-world ML models.

## Implementation

Create a custom `train_test_split_np()` function using **NumPy only**, similar to scikit-learn's `train_test_split`, with full control over:

- Test ratio (e.g., 20% test)
- Shuffle behavior
- Random seed for reproducibility
"""

import numpy as np
class TrainTestSplit:
  def __init__(self,x,y=None,train_size=0.8,seed=None,shuffle=False):
    self.x = x
    self.y = y
    self.train_size = train_size
    self.seed = seed
    self.shuffle = shuffle

  def split(self):
    if not self.shuffle:
        if self.y is None:
            return self.x[:int(self.train_size * len(self.x))], self.x[int(self.train_size * len(self.x)):]
        else:
            return (
                self.x[:int(self.train_size * len(self.x))],
                self.x[int(self.train_size * len(self.x)):],
                self.y[:int(self.train_size * len(self.y))],
                self.y[int(self.train_size * len(self.y)):]
            )
    else:
        if self.seed is not None:
            np.random.seed(self.seed)

        indices = np.arange(len(self.x))
        np.random.shuffle(indices)

        x_shuffled = self.x[indices]
        if self.y is None:
            return (
                x_shuffled[:int(self.train_size * len(self.x))],
                x_shuffled[int(self.train_size * len(self.x)):]
            )
        else:
            y_shuffled = self.y[indices]
            return (
                x_shuffled[:int(self.train_size * len(self.x))],
                x_shuffled[int(self.train_size * len(self.x)):],
                y_shuffled[:int(self.train_size * len(self.y))],
                y_shuffled[int(self.train_size * len(self.y)):]
            )

"""# ðŸ“ˆ Assignment 2: Build Linear Regression from Scratch (Using Your Train-Test Split)

## ðŸ§  What You'll Learn

In this assignment, youâ€™ll build a **Linear Regression model** step-by-step using only **NumPy** â€” and apply it to the training and test sets you created in **Assignment 1**.

You will:

- Use your own `train_test_split_np()` function  
- Fit a line to training data using the **Normal Equation**  
- Make predictions on test data



 ðŸ§ª **The Idea**

Linear Regression tries to find the best-fitting line:

```
y = Î¸â‚€ + Î¸â‚x
```

We use a mathematical formula (Normal Equation) to find the best values for `Î¸â‚€` and `Î¸â‚`:

```
Î¸ = (Xáµ€X)â»Â¹ Xáµ€y
```

Then we use this line to make predictions for new data.

## ðŸ“ Tasks

### âœ… Step 1: Generate the Dataset
"""

import numpy as np

np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

print("X shape:", X.shape)
print("y shape:", y.shape)

"""### âœ… Step 2: Add Intercept Column (xâ‚€ = 1)

> Example:

![Adding 1](https://i.ibb.co/d0zpGpcB/adding-1.png)
"""

ones_array= np.ones((X.shape[0], 1))
X_b =np.hstack((ones_array,X))
np.shape(X_b)

"""### âœ… Step 3: Split the Data

Use your function to split `X` and `y`:

```python
X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_ratio=0.2, seed=42)
```
"""

# X_train, X_test, y_train, y_test = train_test_split_np(X_b, y, test_ratio=0.2, seed=42, shuffle=True)
X_train, X_test, y_train, y_test = TrainTestSplit(X_b, y, train_size=0.8, seed=42, shuffle=True).split()

print(" X_train Shape:", X_train.shape)
print(" X_test Shape:", X_test.shape)
print(" y_train Shape:", y_train.shape)
print(" y_test Shape:", y_test.shape)

"""### âœ… Step 4: Compute Î¸ Using the Normal Equation

![image.png](https://miro.medium.com/v2/resize:fit:1120/1*7ZiWm6xAF4oWiYfWklUMEw.jpeg)
"""

theta = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)
print(theta.shape)
print(theta)

"""### âœ… Step 5: Predict on the Test Set"""

y_pred = X_test @ theta
print(y_pred.shape)
print(y_pred)

"""### âœ… Step 6: Evaluate the Model

Use **Mean Squared Error (MSE)** to evaluate your model's performance:

<img src="https://www.i2tutorials.com/wp-content/media/2019/11/Differences-between-MSE-and-RMSE-1-i2tutorials.jpg" width="400">
"""

MSE = np.mean((y_test - y_pred) ** 2)
print(MSE)